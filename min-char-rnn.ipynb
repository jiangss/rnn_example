{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of minimal character-level language model with a Recurrent Neural Network \n",
    "Reference: https://gist.github.com/karpathy/d4dee566867f8291f086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 43821 characters, 85 unique.\n"
     ]
    }
   ],
   "source": [
    "# data I/O\n",
    "data = open('input.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'T', '”', 'v', '\\x0c', 'l', 'i', '?', '\\n', '1', 'I', 'Q', '6', '/', 'q', '–', 'F', '.', 'O', ' ', 'R', 'P', '[', 'n', 't', '7', 'Y', 'B', 's', ']', 'H', '3', 'k', '2', ')', 'L', '9', 'e', ';', '>', '(', 'X', 'g', '<', 'z', 'J', 'E', 'a', 'K', 'p', 'C', '8', 'd', ',', 'M', 'N', 'D', '’', 'y', 'r', 'A', ':', 'o', 'V', '…', 'U', 'j', '%', '-', 'b', '“', 'W', 'w', '—', '0', 'f', '4', 'u', 'x', '5', 'G', 'm', 'S', '!', 'c']\n",
      "==================================================\n",
      "Chapter 1. Introduction\n",
      "Written by Benjamin Treynor Sloss\n",
      "Edited by Betsy Beyer\n",
      " \n",
      "Hope is not a stra\n"
     ]
    }
   ],
   "source": [
    "print(chars)\n",
    "print(\"=\"*50)\n",
    "print((data[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((vocab_size, 1)) # output bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
